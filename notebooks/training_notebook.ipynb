{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install tensorflow\n",
    "!pip install mmap_ninja\n",
    "!pip install pyyaml\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a yaml config that controls the training process\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "config = {}\n",
    "\n",
    "config['train_dir'] = 'trained_models/alexa_space_in_phonemes'\n",
    "\n",
    "# Each feature_dir should have at least one of the following folders with this structure:\n",
    "#  training/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#\n",
    "#  sampling_weight: Weight for choosing a spectrogram from this set in the batch\n",
    "#  penalty_weight: Penalizing weight for incorrect predictions from this set\n",
    "#  truth: Boolean whether this set has positive samples or negative samples\n",
    "#  truncation_strategy = If spectrograms in the set are longer than necessary for training, how are they truncated\n",
    "#       - random: choose a random portion of the entire spectrogram - useful for long negative samples\n",
    "#       - truncate_start: remove the start of the spectrogram\n",
    "#       - truncate_end: remove the end of the spectrogram\n",
    "#       - split: Split the longer spectrogram into separate spectrograms offset by 100 ms. Only for ambient sets\n",
    "\n",
    "config['features'] = [\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/alexa_phonetic/generated_positive',\n",
    "            'sampling_weight': 1,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': True,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"mmap\",\n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/alexa_phonetic/generated_negative',\n",
    "            'sampling_weight': 1,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/english_speech_background',\n",
    "            'sampling_weight': 2,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/non_english_speech_background',\n",
    "            'sampling_weight': 1,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/dinner_party_background',\n",
    "            'sampling_weight': 2,\n",
    "            'penalty_weight': 3,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/no_speech_background',\n",
    "            'sampling_weight': 1,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/ambient_background',\n",
    "            'sampling_weight': 0.0,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'split',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "    ]\n",
    "\n",
    "# Number of training steps in each iteration - various other settings are configured as lists that corresponds to different steps\n",
    "config['training_steps'] = [30000, 30000,20000,20000]        \n",
    "\n",
    "# Penalizing weight for incorrect class predictions - lists that correspond to training steps\n",
    "config[\"positive_class_weight\"] = [1]               \n",
    "config[\"negative_class_weight\"] = [1]\n",
    "\n",
    "config['learning_rates'] = [0.001, 0.0005,0.0002,0.0001] # Learning rates for Adam optimizer - list that corresponds to training steps\n",
    "config['batch_size'] = 128\n",
    "\n",
    "config['mix_up_augmentation_prob'] =  [0]       # Probability of applying MixUp augmentation - list that corresponds to training steps\n",
    "config['freq_mix_augmentation_prob'] = [0]      # Probability of applying FreqMix augmentation - list that corresponds to training steps\n",
    "config['time_mask_max_size'] = [5]              # SpecAugment - list that corresponds to training steps\n",
    "config['time_mask_count'] = [2]                 # SpecAugment - list that corresponds to training steps\n",
    "config['freq_mask_max_size'] = [5]              # SpecAugment - list that corresponds to training steps\n",
    "config['freq_mask_count'] = [2]                 # SpecAugment - list that corresponds to training steps\n",
    "config['eval_step_interval'] = 500              # Test the validation sets after every this many steps\n",
    "\n",
    "config['clip_duration_ms'] = 1490   # Maximum length of wake word that the streaming model will accept\n",
    "config['window_stride_ms'] = 20     # Fixed setting for default feature generator\n",
    "config['window_size_ms'] = 30       # Fixed setting for default feature generator\n",
    "config['sample_rate'] = 16000       # Fixed setting for default feature generator\n",
    "\n",
    "# The best model weights are chosen first by minimizing the specified minimization metric below the specified target_minimization\n",
    "# Once the target has been met, it chooses the maximum of the maximization metric. Set 'minimization_metric' to None to only maximize\n",
    "# Available metrics:\n",
    "#   - \"loss\" - cross entropy error on validation set\n",
    "#   - \"accuracy\" - accuracy of validation set\n",
    "#   - \"recall\" - recall of validation set\n",
    "#   - \"precision\" - precision of validation set\n",
    "#   - \"false_positive_rate\" - false positive rate of validation set\n",
    "#   - \"false_negative_rate\" - false negative rate of validation set\n",
    "#   - \"ambient_false_positives\" - count of false positives from the split validation_ambient set\n",
    "#   - \"ambient_false_positives_per_hour\" - estimated number of false positives per hour on the split validation_ambient set\n",
    "config['minimization_metric'] = 'ambient_false_positives_per_hour'  # Set to None to disable\n",
    "config['target_minimization'] = 0.5\n",
    "config['maximization_metric'] = 'recall'\n",
    "config['binary_classification'] = False\n",
    "\n",
    "with open(os.path.join('training_parameters.yaml'), 'w') as file:\n",
    "    documents = yaml.dump(config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Loading and analyzing data sets.\n",
      "INFO:absl:training mode has 4796762 spectrograms representing 13172.8 hours of audio\n",
      "INFO:absl:validation mode has 19929 spectrograms representing 24.8 hours of audio\n",
      "INFO:absl:validation_ambient mode has 10 spectrograms representing 5.3 hours of audio\n",
      "INFO:absl:testing mode has 36596 spectrograms representing 33.9 hours of audio\n",
      "INFO:absl:testing_ambient mode has 10 spectrograms representing 5.3 hours of audio\n",
      "INFO:absl:Saving streaming model\n",
      "2024-03-03 11:37:06.656597: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2024-03-03 11:37:06.656630: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-03-03 11:37:06.656636: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-03-03 11:37:06.656684: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-03-03 11:37:06.656706: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 5\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 2\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 2\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 2\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 4\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 4\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 4\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 4\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 4\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 4\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:absl:Function `_wrapped_model` contains input name(s) resource with unsupported characters which will be renamed to model_dense_biasadd_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 44). These functions will not be directly callable after loading.\n",
      "INFO:absl:Writing fingerprint to trained_models/alexa_space_in_phonemes/stream_state_internal/fingerprint.pb\n",
      "INFO:absl:Quantizing and converting streaming model to TFLite\n",
      "2024-03-03 11:37:13.776519: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-03-03 11:37:13.776538: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-03-03 11:37:13.777979: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: trained_models/alexa_space_in_phonemes/stream_state_internal\n",
      "2024-03-03 11:37:13.787070: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-03-03 11:37:13.787089: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: trained_models/alexa_space_in_phonemes/stream_state_internal\n",
      "2024-03-03 11:37:13.801271: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-03-03 11:37:13.809835: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-03-03 11:37:13.971085: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: trained_models/alexa_space_in_phonemes/stream_state_internal\n",
      "2024-03-03 11:37:14.029535: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 251556 microseconds.\n",
      "2024-03-03 11:37:14.101961: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-03 11:37:14.353819: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.353842: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.353844: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.353848: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.353850: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.353851: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.353853: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.353855: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.353857: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.353893: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.353903: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.353915: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.353917: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.353919: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.353921: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.353923: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.353925: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.354470: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.354476: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.354478: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.354480: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-03 11:37:14.354482: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 60, Total Ops 172, % non-converted = 34.88 %\n",
      " * 59 ARITH ops, 1 TF_SAVED_MODEL ops\n",
      "\n",
      "- arith.constant:   59 occurrences  (f32: 50, i32: 9)\n",
      "\n",
      "\n",
      "\n",
      "- tf_saved_model.session_initializer:    1 occurrences\n",
      "\n",
      "\n",
      "  (f32: 14)\n",
      "  (f32: 22)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 11)\n",
      "  (f32: 2)\n",
      "  (f32: 11)\n",
      "  (: 22)\n",
      "2024-03-03 11:37:14.358983: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 0.119 M  ops, equivalently 0.059 M  MACs\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: UINT8\n",
      "2024-03-03 11:37:46.107833: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 0.119 M  ops, equivalently 0.059 M  MACs\n",
      "INFO:absl:Testing the quantized TFLite streaming model\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO:absl:Testing TFLite model on the testing set\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.982018; recall = 0.94863; precision = 0.989286; fpr = 0.00423131; fnr = 0.0513699 (1000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.985507; recall = 0.955473; precision = 0.990385; fpr = 0.00341997; fnr = 0.0445269 (2000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.988004; recall = 0.964461; precision = 0.991184; fpr = 0.00320366; fnr = 0.0355392 (3000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.987503; recall = 0.962894; precision = 0.990458; fpr = 0.00342114; fnr = 0.0371058 (4000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.988202; recall = 0.966399; precision = 0.990269; fpr = 0.0035793; fnr = 0.0336012 (5000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.988835; recall = 0.969898; precision = 0.989558; fpr = 0.00391705; fnr = 0.0301023 (6000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.98943; recall = 0.970696; precision = 0.99039; fpr = 0.00353635; fnr = 0.029304 (7000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.989751; recall = 0.970883; precision = 0.991636; fpr = 0.00310184; fnr = 0.0291174 (8000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.989557; recall = 0.970933; precision = 0.990935; fpr = 0.00337216; fnr = 0.0290674 (9000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.989201; recall = 0.97029; precision = 0.990385; fpr = 0.00359066; fnr = 0.0297101 (10000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.989456; recall = 0.970976; precision = 0.990579; fpr = 0.00351362; fnr = 0.0290237 (11000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.989501; recall = 0.971342; precision = 0.990464; fpr = 0.00356896; fnr = 0.0286576 (12000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.989693; recall = 0.97174; precision = 0.990588; fpr = 0.00350058; fnr = 0.0282597 (13000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.989286; recall = 0.970778; precision = 0.99024; fpr = 0.00365108; fnr = 0.0292216 (14000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.989201; recall = 0.970902; precision = 0.989619; fpr = 0.00386136; fnr = 0.029098 (15000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.989313; recall = 0.970628; precision = 0.990244; fpr = 0.00361788; fnr = 0.0293716 (16000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.989177; recall = 0.970028; precision = 0.990383; fpr = 0.00356853; fnr = 0.0299722 (17000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.989112; recall = 0.969807; precision = 0.990275; fpr = 0.00359712; fnr = 0.0301925 (18000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.989053; recall = 0.969621; precision = 0.990183; fpr = 0.00362319; fnr = 0.0303788 (19000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.989001; recall = 0.969287; precision = 0.990288; fpr = 0.00357856; fnr = 0.030713 (20000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.988953; recall = 0.969274; precision = 0.990014; fpr = 0.0036666; fnr = 0.0307263 (21000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.989137; recall = 0.969682; precision = 0.990303; fpr = 0.00356295; fnr = 0.0303182 (22000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.98887; recall = 0.969152; precision = 0.98993; fpr = 0.00370991; fnr = 0.0308475 (23000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.988792; recall = 0.969022; precision = 0.989713; fpr = 0.00378267; fnr = 0.0309782 (24000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.98872; recall = 0.968759; precision = 0.989661; fpr = 0.00379475; fnr = 0.0312408 (25000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.988693; recall = 0.968446; precision = 0.989921; fpr = 0.00370331; fnr = 0.0315537 (26000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.988778; recall = 0.968678; precision = 0.990022; fpr = 0.0036686; fnr = 0.031322 (27000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.988786; recall = 0.968435; precision = 0.990224; fpr = 0.00358441; fnr = 0.0315652 (28000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.988656; recall = 0.967995; precision = 0.990166; fpr = 0.00360258; fnr = 0.0320051 (29000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.9887; recall = 0.968058; precision = 0.990235; fpr = 0.00357306; fnr = 0.0319422 (30000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.988807; recall = 0.968361; precision = 0.990305; fpr = 0.00354578; fnr = 0.0316388 (31000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.988969; recall = 0.968657; precision = 0.990607; fpr = 0.0034348; fnr = 0.0313433 (32000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.989091; recall = 0.968994; precision = 0.99065; fpr = 0.00341169; fnr = 0.031006 (33000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.989324; recall = 0.969572; precision = 0.990925; fpr = 0.00331099; fnr = 0.0304277 (34000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.989315; recall = 0.969754; precision = 0.990773; fpr = 0.00337533; fnr = 0.0302457 (35000 out of 36596)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.989278; recall = 0.969558; precision = 0.990947; fpr = 0.00332327; fnr = 0.0304419 (36000 out of 36596)\n",
      "INFO:absl:Final TFLite model on the testing set: accuracy = 98.9288%; recall = 96.9785%; precision = 99.0800%; fpr = 0.3383%; fnr = 3.0215%; (N=36596.0)\n",
      "INFO:absl:Testing TFLite model on the testing_ambient set\n",
      "INFO:absl:Final TFLite model on the testing_ambient set: false accepts = 19.0; false accepts per hour = 3.562\n"
     ]
    }
   ],
   "source": [
    "!python -m microwakeword.model_train_eval \\\n",
    "--training_config='training_parameters.yaml' \\\n",
    "--train 0 \\\n",
    "--restore_checkpoint 1 \\\n",
    "--test_tf_nonstreaming 0 \\\n",
    "--test_tflite_nonstreaming 0 \\\n",
    "--test_tflite_streaming 0 \\\n",
    "--test_tflite_streaming_quantized 1 \\\n",
    "--use_weights \"last_weights\" \\\n",
    "inception \\\n",
    "--cnn1_filters '32' \\\n",
    "--cnn1_kernel_sizes '5' \\\n",
    "--cnn1_subspectral_groups '1' \\\n",
    "--cnn2_filters1 '24,24,24' \\\n",
    "--cnn2_filters2 '32,64,96' \\\n",
    "--cnn2_kernel_sizes '3,5,5' \\\n",
    "--cnn2_subspectral_groups '1,1,1' \\\n",
    "--cnn2_dilation '1,1,1' \\\n",
    "--dropout 0.8\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
